{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, auc, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=4)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression: {'max_iter': 100, 'solver': 'lbfgs'}\n",
      "Best Train Accuracy Score for Logistic Regression: 0.9802\n",
      "Best Test Accuracy Score for Logistic Regression: 0.9649\n",
      "Confusion Matrix for Logistic Regression:\n",
      "[[34  0]\n",
      " [ 4 76]]\n"
     ]
    }
   ],
   "source": [
    "# Part a\n",
    "lrgs = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    param_grid={\n",
    "        'solver': ['lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'],\n",
    "        'max_iter': [100, 1000, 2500, 5000],\n",
    "    }\n",
    ")\n",
    "\n",
    "lrgs.fit(X_train, y_train)\n",
    "lrc = lrgs.best_estimator_\n",
    "y_pred = lrc.predict(X_test)\n",
    "acc_a = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Best Parameters for Logistic Regression:', lrgs.best_params_)\n",
    "print('Best Train Accuracy Score for Logistic Regression:', round(lrgs.best_score_, 4))\n",
    "print('Best Test Accuracy Score for Logistic Regression:', round(acc_a, 4))\n",
    "print('Confusion Matrix for Logistic Regression:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for GaussianNB: {'var_smoothing': 0.0533669923120631}\n",
      "Best Train Accuracy Score for GaussianNB: 0.9362\n",
      "Best Test Accuracy Score for GaussianNB: 0.9298\n",
      "Confusion Matrix for GaussianNB:\n",
      "[[32  2]\n",
      " [ 6 74]]\n"
     ]
    }
   ],
   "source": [
    "# Part b\n",
    "nbgs = GridSearchCV(\n",
    "    estimator=GaussianNB(),\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    param_grid={\n",
    "        'var_smoothing': np.logspace(0, -9, 100)\n",
    "    }\n",
    ")\n",
    "\n",
    "nbgs.fit(X_train, y_train)\n",
    "nbc = nbgs.best_estimator_\n",
    "y_pred = nbc.predict(X_test)\n",
    "acc_b = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Best Parameters for GaussianNB:', nbgs.best_params_)\n",
    "print('Best Train Accuracy Score for GaussianNB:', round(nbgs.best_score_, 4))\n",
    "print('Best Test Accuracy Score for GaussianNB:', round(acc_b, 4))\n",
    "print('Confusion Matrix for GaussianNB:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════════════╤═════════════╕\n",
      "│ Feature                 │   AUC Score │\n",
      "╞═════════════════════════╪═════════════╡\n",
      "│ mean concave points     │      0.9415 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ worst concave points    │      0.9290 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ mean concavity          │      0.8890 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ mean area               │      0.8765 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ mean radius             │      0.8640 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ worst concavity         │      0.8599 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ worst radius            │      0.8555 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ worst area              │      0.8555 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ worst perimeter         │      0.8515 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ mean perimeter          │      0.8430 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ area error              │      0.8239 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ radius error            │      0.8176 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ perimeter error         │      0.8176 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ mean compactness        │      0.7989 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ worst compactness       │      0.7676 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ concave points error    │      0.6982 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ worst smoothness        │      0.6813 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ worst symmetry          │      0.6768 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ mean smoothness         │      0.6415 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ mean texture            │      0.6397 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ compactness error       │      0.6309 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ worst fractal dimension │      0.6099 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ concavity error         │      0.5886 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ mean symmetry           │      0.5868 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ worst texture           │      0.5724 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ mean fractal dimension  │      0.5000 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ texture error           │      0.5000 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ smoothness error        │      0.5000 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ symmetry error          │      0.5000 │\n",
      "├─────────────────────────┼─────────────┤\n",
      "│ fractal dimension error │      0.5000 │\n",
      "╘═════════════════════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Part c\n",
    "scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    clf = LogisticRegression(**lrgs.best_params_)\n",
    "    clf.fit(X_train[:, i:i+1], y_train)\n",
    "    # y_pred = clf.predict_proba(X_test[:, i:i+1])[:, 1]\n",
    "    y_pred = clf.predict(X_test[:, i:i+1])\n",
    "    scores.append({\n",
    "        'feature': i,\n",
    "        'score': roc_auc_score(y_test, y_pred),\n",
    "        'model': clf,\n",
    "    })\n",
    "scores.sort(key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "fn = load_breast_cancer().feature_names\n",
    "rows = list(map(lambda x: (fn[x['feature']], x['score']), scores))\n",
    "rows = [['Feature', 'AUC Score']] + rows\n",
    "table = tabulate(rows, headers='firstrow',\n",
    "                 tablefmt='fancy_grid', floatfmt='.4f')\n",
    "\n",
    "with open('P2_c.csv', 'w', encoding='utf-8') as f:\n",
    "    for r in rows:\n",
    "        f.write(','.join(map(lambda x: str(x).replace(',', ''), r)))\n",
    "        f.write('\\n')\n",
    "\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Logistic Regression: 0.9737\n",
      "Improvement for Logistic Regression Compared to Part a: 0.0088\n",
      "Confusion Matrix for Logistic Regression:\n",
      "[[34  0]\n",
      " [ 3 77]]\n",
      "\n",
      "Accuracy Score for GaussianNB: 0.9386\n",
      "Improvement for GaussianNB Compared to Part b: 0.0088\n",
      "Confusion Matrix for GaussianNB:\n",
      "[[32  2]\n",
      " [ 5 75]]\n"
     ]
    }
   ],
   "source": [
    "# Part c\n",
    "\n",
    "# Select best features\n",
    "sf = [s['feature'] for s in scores[:20]]\n",
    "\n",
    "lr = LogisticRegression(**lrgs.best_params_)\n",
    "lr.fit(X_train[:, sf], y_train)\n",
    "y_pred = lr.predict(X_test[:, sf])\n",
    "acc_c_lr = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy Score for Logistic Regression:', round(acc_c_lr, 4))\n",
    "print('Improvement for Logistic Regression Compared to Part a:', round(acc_c_lr - acc_a, 4))\n",
    "print('Confusion Matrix for Logistic Regression:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "nb = GaussianNB(**nbgs.best_params_)\n",
    "nb.fit(X_train[:, sf], y_train)\n",
    "y_pred = nb.predict(X_test[:, sf])\n",
    "acc_c_nb = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy Score for GaussianNB:', round(acc_c_nb, 4))\n",
    "print('Improvement for GaussianNB Compared to Part b:', round(acc_c_nb - acc_b, 4))\n",
    "print('Confusion Matrix for GaussianNB:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part d\n",
    "fm = {s['feature']: s['model'] for s in scores}\n",
    "\n",
    "\n",
    "def extract_features(X):\n",
    "    X_ = X.copy()\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            X_[i, j] = fm[j].predict_proba(X[i:i+1, j:j+1])[0, 1]\n",
    "    return X_\n",
    "\n",
    "\n",
    "X_train_p = extract_features(X_train)\n",
    "X_test_p = extract_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Logistic Regression: 0.9298\n",
      "AUC Score for Logistic Regression: 0.95\n",
      "Improvement for Logistic Regression Compared to Part a: -0.0351\n",
      "Improvement for Logistic Regression Compared to Part c: -0.0439\n",
      "Confusion Matrix for Logistic Regression:\n",
      "[[34  0]\n",
      " [ 8 72]]\n",
      "\n",
      "Accuracy Score for GaussianNB: 0.886\n",
      "AUC Score for GaussianNB: 0.9103\n",
      "Improvement for GaussianNB Compared to Part b: -0.0439\n",
      "Improvement for GaussianNB Compared to Part c: -0.0526\n",
      "Confusion Matrix for GaussianNB:\n",
      "[[33  1]\n",
      " [12 68]]\n",
      "\n",
      "Accuracy Score for MultinomialNB: 0.9123\n",
      "AUC Score for MultinomialNB: 0.8868\n",
      "Confusion Matrix for MultinomialNB:\n",
      "[[28  6]\n",
      " [ 4 76]]\n"
     ]
    }
   ],
   "source": [
    "# Part d\n",
    "lr = LogisticRegression(**lrgs.best_params_)\n",
    "lr.fit(X_train_p, y_train)\n",
    "y_pred = lr.predict(X_test_p)\n",
    "acc_d_lr = accuracy_score(y_test, y_pred)\n",
    "auc_d_lr = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy Score for Logistic Regression:', round(acc_d_lr, 4))\n",
    "print('AUC Score for Logistic Regression:', round(auc_d_lr, 4))\n",
    "print('Improvement for Logistic Regression Compared to Part a:', round(acc_d_lr - acc_a, 4))\n",
    "print('Improvement for Logistic Regression Compared to Part c:', round(acc_d_lr - acc_c_lr, 4))\n",
    "print('Confusion Matrix for Logistic Regression:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "nb = GaussianNB(**nbgs.best_params_)\n",
    "nb.fit(X_train_p, y_train)\n",
    "y_pred = nb.predict(X_test_p)\n",
    "acc_d_nb = accuracy_score(y_test, y_pred)\n",
    "auc_d_nb = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy Score for GaussianNB:', round(acc_d_nb, 4))\n",
    "print('AUC Score for GaussianNB:', round(auc_d_nb, 4))\n",
    "print('Improvement for GaussianNB Compared to Part b:', round(acc_d_nb - acc_b, 4))\n",
    "print('Improvement for GaussianNB Compared to Part c:', round(acc_d_nb - acc_c_nb, 4))\n",
    "print('Confusion Matrix for GaussianNB:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_p, y_train)\n",
    "y_pred = mnb.predict(X_test_p)\n",
    "acc_d_mnb = accuracy_score(y_test, y_pred)\n",
    "auc_d_mnb = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy Score for MultinomialNB:', round(acc_d_mnb, 4))\n",
    "print('AUC Score for MultinomialNB:', round(auc_d_mnb, 4))\n",
    "print('Confusion Matrix for MultinomialNB:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b324498af64d22b4773901be112d66dec816013b7f64fed368c8550f7daba2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
